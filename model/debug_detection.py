#!/usr/bin/env python3
"""
è°ƒè¯•æ£€æµ‹ç»“æœï¼Œåˆ†æä¸ºä»€ä¹ˆæ¨¡å‹æ— æ³•æ£€æµ‹åˆ°éº»å°†ç‰Œ
"""

import cv2
import numpy as np
from pathlib import Path
import logging
import argparse
import matplotlib.pyplot as plt
from typing import List, Dict, Tuple

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DetectionDebugger:
    """æ£€æµ‹è°ƒè¯•å™¨"""
    
    def __init__(self, model_path: str):
        self.model_path = Path(model_path)
        self.model = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            from ultralytics import YOLO
            self.model = YOLO(str(self.model_path))
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_path}")
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def test_multiple_thresholds(self, image_path: Path, thresholds: List[float] = None):
        """æµ‹è¯•å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼"""
        if thresholds is None:
            thresholds = [0.01, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5]
        
        logger.info(f"ğŸ” æµ‹è¯•å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼: {image_path.name}")
        
        results_summary = []
        
        for threshold in thresholds:
            results = self.model(str(image_path), conf=threshold, verbose=False)
            
            detections = 0
            for result in results:
                if result.boxes is not None:
                    detections = len(result.boxes)
                    break
            
            results_summary.append({
                'threshold': threshold,
                'detections': detections
            })
            
            logger.info(f"  ç½®ä¿¡åº¦ {threshold:.2f}: {detections} ä¸ªæ£€æµ‹")
        
        return results_summary
    
    def visualize_low_confidence_detections(self, image_path: Path, threshold: float = 0.01):
        """å¯è§†åŒ–ä½ç½®ä¿¡åº¦æ£€æµ‹ç»“æœ"""
        logger.info(f"ğŸ¨ å¯è§†åŒ–ä½ç½®ä¿¡åº¦æ£€æµ‹ (threshold={threshold}): {image_path.name}")
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(str(image_path))
        if image is None:
            logger.error(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")
            return None
        
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # è¿è¡Œæ£€æµ‹
        results = self.model(str(image_path), conf=threshold, verbose=False)
        
        # ç»˜åˆ¶æ£€æµ‹ç»“æœ
        annotated_image = image_rgb.copy()
        
        detection_info = []
        
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for i in range(len(boxes)):
                    # è·å–åæ ‡å’Œä¿¡æ¯
                    x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
                    conf = float(boxes.conf[i].cpu().numpy())
                    cls = int(boxes.cls[i].cpu().numpy())
                    
                    # é¢œè‰²æ ¹æ®ç½®ä¿¡åº¦å˜åŒ–
                    if conf >= 0.5:
                        color = (0, 255, 0)  # ç»¿è‰² - é«˜ç½®ä¿¡åº¦
                    elif conf >= 0.25:
                        color = (255, 255, 0)  # é»„è‰² - ä¸­ç½®ä¿¡åº¦
                    else:
                        color = (255, 0, 0)  # çº¢è‰² - ä½ç½®ä¿¡åº¦
                    
                    # ç»˜åˆ¶è¾¹ç•Œæ¡†
                    cv2.rectangle(annotated_image, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
                    
                    # æ·»åŠ æ ‡ç­¾
                    label = f"cls_{cls}_{conf:.2f}"
                    cv2.putText(annotated_image, label, (int(x1), int(y1)-10), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                    
                    detection_info.append({
                        'bbox': [x1, y1, x2, y2],
                        'confidence': conf,
                        'class': cls,
                        'size': f"{int(x2-x1)}x{int(y2-y1)}"
                    })
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœ
        output_path = image_path.parent / f"debug_{image_path.stem}_conf{threshold}.jpg"
        cv2.imwrite(str(output_path), cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR))
        
        logger.info(f"âœ… å¯è§†åŒ–ç»“æœä¿å­˜: {output_path}")
        logger.info(f"ğŸ“Š æ£€æµ‹ç»Ÿè®¡: {len(detection_info)} ä¸ªå¯¹è±¡")
        
        for i, info in enumerate(detection_info):
            logger.info(f"  æ£€æµ‹{i+1}: ç½®ä¿¡åº¦={info['confidence']:.3f}, å°ºå¯¸={info['size']}, ç±»åˆ«={info['class']}")
        
        return annotated_image, detection_info
    
    def analyze_training_vs_real_images(self, training_image_dir: Path, real_image_path: Path):
        """åˆ†æè®­ç»ƒå›¾åƒä¸çœŸå®å›¾åƒçš„å·®å¼‚"""
        logger.info("ğŸ” åˆ†æè®­ç»ƒæ•°æ®ä¸çœŸå®å›¾åƒçš„å·®å¼‚...")
        
        # åˆ†æçœŸå®å›¾åƒ
        real_image = cv2.imread(str(real_image_path))
        real_rgb = cv2.cvtColor(real_image, cv2.COLOR_BGR2RGB)
        
        logger.info(f"çœŸå®å›¾åƒ: {real_image_path.name}")
        logger.info(f"  å°ºå¯¸: {real_image.shape[1]}x{real_image.shape[0]}")
        logger.info(f"  äº®åº¦: {np.mean(real_rgb):.1f}")
        
        # åˆ†æè®­ç»ƒå›¾åƒæ ·æœ¬
        training_images = list(training_image_dir.glob("*.jpg"))[:5]  # åˆ†æå‰5å¼ 
        
        logger.info(f"\nè®­ç»ƒå›¾åƒæ ·æœ¬åˆ†æ:")
        for train_img_path in training_images:
            train_img = cv2.imread(str(train_img_path))
            if train_img is not None:
                train_rgb = cv2.cvtColor(train_img, cv2.COLOR_BGR2RGB)
                logger.info(f"  {train_img_path.name}: å°ºå¯¸={train_img.shape[1]}x{train_img.shape[0]}, äº®åº¦={np.mean(train_rgb):.1f}")
    
    def suggest_improvements(self, image_path: Path):
        """æä¾›æ”¹è¿›å»ºè®®"""
        logger.info("ğŸ’¡ æ”¹è¿›å»ºè®®:")
        
        # æµ‹è¯•å¤šä¸ªé˜ˆå€¼
        results = self.test_multiple_thresholds(image_path)
        
        max_detections = max(r['detections'] for r in results)
        best_threshold = None
        
        for r in results:
            if r['detections'] == max_detections and max_detections > 0:
                best_threshold = r['threshold']
                break
        
        if max_detections == 0:
            logger.info("1. â— æ¨¡å‹å®Œå…¨æ— æ³•æ£€æµ‹åˆ°ç›®æ ‡ï¼Œå»ºè®®:")
            logger.info("   - æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡")
            logger.info("   - ä½¿ç”¨çœŸå®æ¸¸æˆæˆªå›¾ä½œä¸ºèƒŒæ™¯è¿›è¡Œåˆæˆ")
            logger.info("   - è°ƒæ•´éº»å°†ç‰Œçš„å¤–è§‚ä½¿å…¶æ›´æ¥è¿‘çœŸå®æ¸¸æˆ")
            logger.info("   - è€ƒè™‘ä½¿ç”¨æ›´å¤šçœŸå®æ ‡æ³¨æ•°æ®")
        else:
            logger.info(f"2. âœ… åœ¨ç½®ä¿¡åº¦ {best_threshold} æ—¶æ£€æµ‹åˆ° {max_detections} ä¸ªå¯¹è±¡")
            logger.info("   å»ºè®®é™ä½ç½®ä¿¡åº¦é˜ˆå€¼æˆ–æ”¹è¿›è®­ç»ƒæ•°æ®")
        
        return best_threshold

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è°ƒè¯•æ£€æµ‹ç»“æœ')
    parser.add_argument('--model', default='runs/train/simple_mahjong_tiles_n/weights/best.pt',
                       help='æ¨¡å‹è·¯å¾„')
    parser.add_argument('--image', required=True,
                       help='è¦è°ƒè¯•çš„å›¾åƒè·¯å¾„')
    parser.add_argument('--training_dir', default='simple_synthetic_dataset/images',
                       help='è®­ç»ƒå›¾åƒç›®å½•')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥æ–‡ä»¶
    model_path = Path(args.model)
    image_path = Path(args.image)
    training_dir = Path(args.training_dir)
    
    if not model_path.exists():
        logger.error(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    if not image_path.exists():
        logger.error(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    # åˆ›å»ºè°ƒè¯•å™¨
    debugger = DetectionDebugger(str(model_path))
    
    # 1. æµ‹è¯•å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼
    logger.info("=" * 50)
    logger.info("ğŸ” æ­¥éª¤1: æµ‹è¯•å¤šä¸ªç½®ä¿¡åº¦é˜ˆå€¼")
    results = debugger.test_multiple_thresholds(image_path)
    
    # 2. å¯è§†åŒ–ä½ç½®ä¿¡åº¦æ£€æµ‹
    logger.info("=" * 50)
    logger.info("ğŸ¨ æ­¥éª¤2: å¯è§†åŒ–ä½ç½®ä¿¡åº¦æ£€æµ‹")
    debugger.visualize_low_confidence_detections(image_path, 0.01)
    debugger.visualize_low_confidence_detections(image_path, 0.1)
    
    # 3. åˆ†æè®­ç»ƒæ•°æ®vsçœŸå®æ•°æ®
    if training_dir.exists():
        logger.info("=" * 50)
        logger.info("ğŸ“Š æ­¥éª¤3: åˆ†æè®­ç»ƒæ•°æ®ä¸çœŸå®å›¾åƒå·®å¼‚")
        debugger.analyze_training_vs_real_images(training_dir, image_path)
    
    # 4. æä¾›æ”¹è¿›å»ºè®®
    logger.info("=" * 50)
    logger.info("ğŸ’¡ æ­¥éª¤4: æ”¹è¿›å»ºè®®")
    best_threshold = debugger.suggest_improvements(image_path)
    
    logger.info("=" * 50)
    logger.info("âœ… è°ƒè¯•å®Œæˆ!")
    logger.info(f"ğŸ“ æŸ¥çœ‹ç”Ÿæˆçš„è°ƒè¯•å›¾åƒ: debug_{image_path.stem}_conf*.jpg")

if __name__ == "__main__":
    main()