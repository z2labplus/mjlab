#!/usr/bin/env python3
"""
éº»å°†åŒºåŸŸæ£€æµ‹è®­ç»ƒå¿«é€Ÿå¯åŠ¨è„šæœ¬
ä¸€é”®å®Œæˆä»æ•°æ®è½¬æ¢åˆ°æ¨¡å‹è®­ç»ƒçš„å…¨æµç¨‹
"""

import os
import sys
import subprocess
import logging
from pathlib import Path
import argparse

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class RegionTrainingPipeline:
    """åŒºåŸŸæ£€æµ‹è®­ç»ƒæµæ°´çº¿"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.source_dir = self.base_dir / "all_labeled_images"
        self.dataset_dir = self.base_dir / "yolo_dataset"
        
    def check_dependencies(self):
        """æ£€æŸ¥ä¾èµ–"""
        logger.info("ğŸ” æ£€æŸ¥ä¾èµ–...")
        
        required_packages = ['ultralytics', 'opencv-python', 'torch', 'torchvision']
        missing_packages = []
        
        for package in required_packages:
            try:
                __import__(package.replace('-', '_'))
                logger.info(f"âœ… {package}")
            except ImportError:
                missing_packages.append(package)
                logger.error(f"âŒ {package}")
        
        if missing_packages:
            logger.error(f"ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
            logger.info("è¯·è¿è¡Œ: pip install ultralytics opencv-python torch torchvision")
            return False
        
        return True
    
    def check_data(self):
        """æ£€æŸ¥æ•°æ®"""
        logger.info("ğŸ“Š æ£€æŸ¥è®­ç»ƒæ•°æ®...")
        
        if not self.source_dir.exists():
            logger.error(f"æºæ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.source_dir}")
            return False
        
        # ç»Ÿè®¡æ–‡ä»¶
        json_files = list(self.source_dir.glob("*.json"))
        jpg_files = list(self.source_dir.glob("*.jpg"))
        
        logger.info(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ ‡æ³¨æ–‡ä»¶")
        logger.info(f"æ‰¾åˆ° {len(jpg_files)} ä¸ªJPGå›¾ç‰‡æ–‡ä»¶")
        
        if len(json_files) == 0:
            logger.error("æ²¡æœ‰æ‰¾åˆ°JSONæ ‡æ³¨æ–‡ä»¶!")
            return False
        
        if len(jpg_files) == 0:
            logger.error("æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶!")
            return False
        
        if len(json_files) != len(jpg_files):
            logger.warning(f"æ ‡æ³¨æ–‡ä»¶å’Œå›¾ç‰‡æ–‡ä»¶æ•°é‡ä¸åŒ¹é…: {len(json_files)} vs {len(jpg_files)}")
        
        return True
    
    def convert_data(self):
        """è½¬æ¢æ•°æ®æ ¼å¼"""
        logger.info("ğŸ”„ è½¬æ¢æ•°æ®æ ¼å¼...")
        
        cmd = [
            sys.executable, "convert_xanylabeling_to_yolo.py",
            "--source", str(self.source_dir),
            "--output", str(self.dataset_dir),
            "--train_ratio", "0.8"
        ]
        
        try:
            result = subprocess.run(cmd, cwd=self.base_dir, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info("âœ… æ•°æ®è½¬æ¢æˆåŠŸ")
                logger.info(result.stdout)
                return True
            else:
                logger.error("âŒ æ•°æ®è½¬æ¢å¤±è´¥")
                logger.error(result.stderr)
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ•°æ®è½¬æ¢å¤±è´¥: {e}")
            return False
    
    def train_model(self, model_size='n', epochs=100, batch=16):
        """è®­ç»ƒæ¨¡å‹"""
        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹ (å¤§å°: {model_size}, è½®æ•°: {epochs})...")
        
        cmd = [
            sys.executable, "train_region_detector.py",
            "--dataset", str(self.dataset_dir),
            "--model_size", model_size,
            "--epochs", str(epochs),
            "--batch", str(batch),
            "--device", "cpu"  # æ˜ç¡®æŒ‡å®šä½¿ç”¨CPUï¼Œé¿å…autoçš„é—®é¢˜
        ]
        
        try:
            # å®æ—¶æ˜¾ç¤ºè¾“å‡º
            process = subprocess.Popen(cmd, cwd=self.base_dir, 
                                     stdout=subprocess.PIPE, 
                                     stderr=subprocess.STDOUT,
                                     text=True, bufsize=1, universal_newlines=True)
            
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(output.strip())
            
            return_code = process.poll()
            
            if return_code == 0:
                logger.info("âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸ")
                return True
            else:
                logger.error("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False
    
    def find_best_model(self):
        """æŸ¥æ‰¾æœ€ä½³æ¨¡å‹"""
        runs_dir = self.base_dir / "runs" / "train"
        
        if not runs_dir.exists():
            return None
        
        # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒç»“æœ
        train_dirs = [d for d in runs_dir.iterdir() if d.is_dir() and d.name.startswith('mahjong_regions')]
        
        if not train_dirs:
            return None
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
        latest_dir = sorted(train_dirs, key=lambda x: x.stat().st_mtime, reverse=True)[0]
        best_model = latest_dir / "weights" / "best.pt"
        
        return best_model if best_model.exists() else None
    
    def test_model(self, test_source=None):
        """æµ‹è¯•æ¨¡å‹"""
        logger.info("ğŸ§ª æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹...")
        
        # æŸ¥æ‰¾æ¨¡å‹
        best_model = self.find_best_model()
        if not best_model:
            logger.error("æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
            return False
        
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {best_model}")
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæµ‹è¯•æºï¼Œä½¿ç”¨éªŒè¯é›†çš„ç¬¬ä¸€å¼ å›¾ç‰‡
        if not test_source:
            val_images = list((self.dataset_dir / "images" / "val").glob("*.jpg"))
            if val_images:
                test_source = str(val_images[0])
            else:
                logger.error("æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
                return False
        
        cmd = [
            sys.executable, "test_region_detector.py",
            "--model", str(best_model),
            "--source", test_source,
            "--conf", "0.5"
        ]
        
        try:
            result = subprocess.run(cmd, cwd=self.base_dir, capture_output=True, text=True)
            
            if result.returncode == 0:
                logger.info("âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸ")
                logger.info(result.stdout)
                return True
            else:
                logger.error("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥")
                logger.error(result.stderr)
                return False
                
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def run_full_pipeline(self, model_size='n', epochs=100, batch=16, test_source=None):
        """è¿è¡Œå®Œæ•´æµæ°´çº¿"""
        logger.info("ğŸ¯ å¼€å§‹éº»å°†åŒºåŸŸæ£€æµ‹è®­ç»ƒæµæ°´çº¿")
        logger.info("=" * 60)
        
        steps = [
            ("æ£€æŸ¥ä¾èµ–", self.check_dependencies),
            ("æ£€æŸ¥æ•°æ®", self.check_data),
            ("è½¬æ¢æ•°æ®", self.convert_data),
            ("è®­ç»ƒæ¨¡å‹", lambda: self.train_model(model_size, epochs, batch)),
            ("æµ‹è¯•æ¨¡å‹", lambda: self.test_model(test_source))
        ]
        
        for step_name, step_func in steps:
            logger.info(f"\nğŸ“‹ æ­¥éª¤: {step_name}")
            logger.info("-" * 30)
            
            success = step_func()
            
            if not success:
                logger.error(f"âŒ æ­¥éª¤ '{step_name}' å¤±è´¥ï¼Œæµæ°´çº¿åœæ­¢")
                return False
            
            logger.info(f"âœ… æ­¥éª¤ '{step_name}' å®Œæˆ")
        
        logger.info("\nğŸ‰ è®­ç»ƒæµæ°´çº¿å®Œæˆ!")
        
        # æ˜¾ç¤ºç»“æœä¿¡æ¯
        best_model = self.find_best_model()
        if best_model:
            logger.info(f"ğŸ“‚ æœ€ä½³æ¨¡å‹è·¯å¾„: {best_model}")
            logger.info(f"ğŸ“Š è®­ç»ƒç»“æœç›®å½•: {best_model.parent.parent}")
        
        return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='éº»å°†åŒºåŸŸæ£€æµ‹è®­ç»ƒæµæ°´çº¿')
    parser.add_argument('--model_size', default='n', choices=['n', 's', 'm', 'l', 'x'],
                       help='æ¨¡å‹å¤§å° (n=æœ€å¿«, x=æœ€å‡†ç¡®)')
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch', type=int, default=16,
                       help='æ‰¹å¤§å°')
    parser.add_argument('--test_source', 
                       help='æµ‹è¯•å›¾ç‰‡/è§†é¢‘è·¯å¾„')
    parser.add_argument('--step', choices=['convert', 'train', 'test', 'full'],
                       default='full', help='æ‰§è¡Œç‰¹å®šæ­¥éª¤')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµæ°´çº¿
    pipeline = RegionTrainingPipeline()
    
    if args.step == 'convert':
        pipeline.convert_data()
    elif args.step == 'train':
        pipeline.train_model(args.model_size, args.epochs, args.batch)
    elif args.step == 'test':
        pipeline.test_model(args.test_source)
    else:  # full
        pipeline.run_full_pipeline(args.model_size, args.epochs, args.batch, args.test_source)

if __name__ == "__main__":
    main()